---
layout: framework_eng
title: Project
---

<style>
    .text {
        font-size: 18px;
    }
</style>

<h2>The project</h2>

<strong>
    <p class="text"> 
        The analysis of health data plays a crucial role in medical research and enables 
        more precise diagnoses, more effective treatments and future-oriented care. 
        However, given the sensitivity of such data, careful handling is essential to 
        ensure both legal requirements and the protection of patient privacy. This 
        challenge is particularly evident in the context of training artificial 
        intelligence (AI) models, where extensive data sets are necessary to obtain 
        reliable results.
    </p>
</strong>

<img src="../assets/images/how_it_works.png" alt="Beschreibung des Bildes">
<figcaption>
    The image shows the difference between distributed analysis and data aggregation: 
    on the left are several nodes of a decentralized analysis, while on the right the 
    data streams flow to a central location.
</figcaption>
<br>

<p class="text">
    The PrivateAIM (Privacy-preserving Analytics in Medicine) method platform addresses 
    precisely this interface and attempts to pave a balanced path between data protection 
    and data use. It follows the principle of 'code to the data', in which the health data 
    remain in the protected environments of the university hospitals and only the analysis 
    algorithms are exchanged. This form of decentralized analysis ensures that data never 
    leaves its secure environment. Patients' identities and sensitive health information 
    thus remain fully protected and cannot be viewed by researchers at any time.

    To achieve this goal, the PrivateAIM project is dedicated to developing customized AI 
    methods, risk models and federation mechanisms. These innovations are incorporated into 
    the newly developed software platform FLAME (Federated Learning and Analysis in Medicine) 
    and thus form the technological core for secure, distributed evaluations in the Medical 
    Informatics Initiative (MII).
</p>
<br>
<p class="text">
    Das PrivateAIM-Konsortium bringt eine Vielzahl von Expertinnen und Experten 
    aus der Universitätsmedizin und anderen Institutionen zusammen. Insgesamt 
    sind 17 Partner aus allen vier MII-Konsortien, einschließlich drei MII-geförderter 
    Nachwuchsgruppen, am Projekt beteiligt. Ein besonderes Augenmerk liegt auf der 
    aktiven Einbindung von Patientinnen und Patienten und anderen Interessengruppen, 
    um vielschichtige Perspektiven in das Projekt einzubringen.

    Das Konsortium setzt sich intensiv dafür ein, den Bürgerinnen und Bürgern die 
    technischen Verfahren für datenschutzkonforme, föderierte Auswertungen und das 
    Machine Learning (ML) verständlich darzulegen. Ziel ist es, die Sicherheitsgarantien 
    und den Schutz, den diese Methoden bieten, transparent und nachvollziehbar zu 
    kommunizieren. Hierzu werden Patientinnen und Patienten und die breite Öffentlichkeit 
    durch leicht verständliche Informationsmaterialien über die Arbeit von PrivateAIM 
    aufgeklärt. Darüber hinaus werden Patientinnen und Patienten sowie weitere Stakeholder 
    von Beginn an in Workshops eingebunden, um Konzeption, Implementierung und Bewertung 
    der datenschutzfreundlichen föderierten Methoden aktiv mitzugestalten.
</p>
<br>
<p class="text">
    Bevor die Ergebnisse des Projekts in die Praxis umgesetzt werden, wird FLAME 
    sowohl mit Benchmark-Datensätzen als auch in realen Anwendungen auf Herz und 
    Nieren geprüft. Eine breite Akzeptanz wird durch ein mehrstufiges Rollout-Konzept 
    angestrebt, welches die Datenintegrationszentren aller MII-Konsortien einbezieht. 
    Die Bereitstellung als Open-Source-Software und die Zusammenarbeit mit verwandten 
    Projekten tragen maßgeblich zur Nachhaltigkeit des Projekts bei.

    Über die nächsten vier Jahre hinweg wird die Methodenplattform PrivateAIM mit 
    FLAME in der MII eine zusätzliche Möglichkeit bieten, medizinische Daten 
    standortübergreifend effizient und sicher auszuwerten. Insbesondere für 
    moderne KI-Methoden erschließen sich damit die dringend benötigten umfangreichen 
    Datenmengen, ohne dabei den zentralen Aspekt des Datenschutzes für die Patientinnen 
    und Patienten zu vernachlässigen.
</p>
